# -*- coding: utf-8 -*-
"""Sistem Rekomendasi_Merri Putri.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GJIfm77qlVLFZid20karNS7RfkaWHjec

# Proyek akhir : Membuat Model Sistem Rekomendasi Film
- Nama : Merri Putri Panggabean
- Cohort ID : MC404D5X0047
- Email : merypanggabean219@gmail.com

## Project Overview
### Latar Belakang
Dalam era digital saat ini, perkembangan teknologi telah mengubah cara manusia mengakses dan mengosumsi hiburan, termasuk dalam hal menonton film. Dengan meningkatnya jumlah film yang dirilis setiap tahunnya, konsumen menghadapi tantangan dalam memilih film yang sesuai dengan preferensi mereka. Hal ini membuka peluang besar bagi pengembangan sistem rekomendasi berbasis data untuk membantu pengguna dalam menentukan film yang relevan. Maka dataset yang akan penulis analisis dan uji sistem pada rekomendasi film ialah **MovieLens**.

Dataset MovieLens menyajikan informasi tentang penilaian (rating) film yang diberikan oleh pengguna terhadap berbagai film. dataset ini telah digunakan secara luas dalam penelitian sistem rekomendasi karena kelengkapan dan kestabilannya dalam menyajikan hubungan antara pengguna dan item [1]. Melalui analisis lebih lanjut, penulis akan mengembangkan berbagai model prediksi seperti **Collaborative Filtering** dan **Content Based Filtering**.

Permasalahn utama yang ingin diselesaikan dalam proyek ini adalah **bagaimana memanfaatkan data historis dari penilaian pengguna** untuk membangun model prediktif yang mampu merekomendasikan film yang relevan bagi pengguna. Hal ini penting mengingat sistem rekomendasi pada peningkatan pengalaman pengguna, tetapi juga berdampak pada peningkatan keterlibaan dan keutungan platform layanan streaming[2]. menggunakan matrix factorization atau pendekatan deep learning seperti autoencoders yang efektif dalam menangkap pola preferensi pengguna[3]. maka dengan itu, penulis akan berfokus pada analisis dan pemodelan serta evaluasi model untuk mendapatkan hasil yang optimal.

### Referensi
[1] F. M. Harper and J. A. Konstan, “The MovieLens Datasets: History and Context,” ACM Transactions on Interactive Intelligent Systems (TiiS), vol. 5, no. 4, Article 19, Dec. 2015.

[2] X. Su and T. M. Khoshgoftaar, "A Survey of Collaborative Filtering Techniques," Advances in Artificial Intelligence, vol. 2009, Article ID 421425, 2009. doi:10.1155/2009/421425

[3] Y. Koren, R. Bell, and C. Volinsky, “Matrix Factorization Techniques for Recommender Systems,” IEEE Computer, vol. 42, no. 8, pp. 30–37, Aug. 2009. doi:10.1109/MC.2009.263

# Business Understanding
Pada tahap ini, penulis menjelaskan pemahaman-pemahaman dalam dataset yang akan di analisis lebih lanjut. sebagai berikut :     
  ### Problem Statment
- Mempelajari prefensi pengguna berdasarkan interaksi historis (rating).
- Membangun model yang mampu memberikan rekomendasi film yang relevan.
- Menentukan algoritma yang efektif untuk meningkatkan akurasi prediksi film yang diminati pengguna.

### Goals
- Menganalisis data MovieLens lebih lanjut untuk memahami pola perilaku pengguna terhadap film.
- Membuat perbandingan dengan beberapa model misalnya **Content-Based Filtering** dan **Collaborative Filtering**.
- Menggunakan **RMSE, Precesion, F-1 dan Recall** untuk mengevaluasi setiap model.

### Solusi Approach
setelah mendapatkan pernyataan masalah dan tujuan dalam MovieLens, maka penulis perlu mengatasi masalah yang diindetifikasi pada solusi approach. beberapa penjelesannya :  

**1. Content-Based-Filtering**

Pada model pertama yang akan penulis analisa lebih lanjut untuk menganlisis fitur dari rating seperti `genres`. Rekomendasi film akan diberikan berdasarkan kesamaan antara film yang sering diminati dan karakteristik yang sama.

Langkah-langkahnya ialah :

- Melakukan ekstraksi fitur konten dari fitur `genre`.
- Membuat representasi vector pada setiap film menggunakan TF-IDF.
- Menghitung kesamaan antar `genre` menggunakan **Cosine similarity**.
- Memberikan hasil rekomendasi berdasarkan film yang paling diminati.

**2. Collaborative Fitering**

Pada model kedua ini, Penulis melakukan suatu analisis lebih lanjut untuk memberikan rekomendasi berdasarkan kesamaan perilaku antar pengguna. pendekatan ini memanfaatkan fitur rating yang diberikan oleh pengguna terhadap film dan menemukan pola kemiripan antar pengguna atau genre.

Langkah-langkahnya ialah :    

- Menggunakan User-item-rating matrix dari data MoviLens.
- Menerapkan motode **User-Based** dan **Item-Based** pada Collaborative Filtering.
- Menggunakan **matrix factorization**.
- Memberikan hasil rekomendasi berdasarkan pola rating dari pengguna yang serupa.

# Data Understanding

## Import Library

Pada tahap ini, penulis melakukan import library yang dimana library dapat menampilkan dataset, visualisasi data, melatih model dan evaluasi model
"""

# Commented out IPython magic to ensure Python compatibility.
# Import module Untuk pengolahan data
from google.colab import files
import numpy as np
import pandas as pd
from google.colab import drive
from zipfile import ZipFile
import os
from collections import Counter
from itertools import chain


from tensorflow import keras
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.utils import resample
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

# Import Module Untuk visualisasi data
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

"""Sebelum melakukan Load dataset pada `MovieLens` maka penulis perlu untuk menghubungkan drive ke goggle colab untuk menampilkan dan melakukan ekstrak zip dari direktori yang penulis simpan."""

# Menghubungkan drive ke gogle colab
from google.colab import drive
drive.mount('/content/drive')

# Melakukan ekstrak ZIP
# Menentukan file yang disimpan
file_name = "/content/drive/MyDrive/Colab Notebooks/archive (11).zip"

# Ekstrak file
if os.path.exists(file_name):
    with ZipFile(file_name, 'r') as zip_ref:
        zip_ref.extractall('/content/')  # atau ganti path jika mau ekstrak ke folder tertentu
        print("Ekstraksi selesai.")
else:
    print("File ZIP tidak ditemukan. Pastikan path-nya benar.")

"""## Load Dataset"""

# melakukan Load dataset untuk rekomendasi film
movie = pd.read_csv('movies.csv')
rating = pd.read_csv('ratings.csv')
link = pd.read_csv('links.csv')
tag = pd.read_csv('tags.csv')
print("Datasetnya berhasil dimuat")

"""setelah melakukan load dataset menggunakan fungsi `.read.csv()` maka akan menampilkan *dataset berhasil dimuat*. pada analisa lebih lanjut. penulis menggunakan data `ratings.csv` `link`, `tag` dan `movies.csv` untuk visualisasi data, melatih model dan evaluasi model untuk lebih lanjut.


"""

# Menampilkan jumlah baris dan kolom dari setiap dataset
print(f"Jumlah data Movie: {movie.shape}")
print(f"Jumlah data Rating: {rating.shape}")
print(f"Jumlah data Rating: {tag.shape}")
print(f"Jumlah data Rating: {link.shape}")

"""**Menampilkan jumlah baris dan kolom**

Pada tahap ini, penulis melakukan untuk menampilkan banyaknya jumlah baris dan kolom pada dataset `movie`, `link` `tag` dan `rating` dengan menggunakan fungsi `.shape()`.
"""

# Melihat dan menampilkan jumlah data pada setiap dataset yang berkontrabusi.
print('Jumlah data Link : ', len(link.movieId.unique()))
print('Jumlah data Film : ', len(movie.movieId.unique()))
print('Jumlah data Ratings dari user : ', len(rating.userId.unique()))
print('Jumlah data Ratings dari user : ', len(rating.movieId.unique()))
print('Jumlah data Tag : ', len(tag.movieId.unique()))

"""**Menampilkan jumlah data**

Pada tahap ini, penulis menggunakan fungsi `.len()` yang berfungsi untuk mengetahui jumlah data pada semua dataset dengan melihat `.unique` yang berhubungan satu sama lain. dimana dari hasil yang penulis dapat bahwa

- `Jumlah data link :`  **`9125`**
- `Jumlah data buku :`  **`9125`**
- `Jumlah data ratings dari user :`  **`671`**
- `Jumlah data ratings dari user :`  **`9066`**
- `Jumlah data tag :`  **`689`**

## Univariate Exploratory Data Analysis

### Data Movie
"""

# menampilkan sample data dengan 5 baris pertama pada data Movie
movie.head(5)

"""**Menampilkan sample data**

Pada tahap ini, penulis menggunakan fungsi `.head()` untuk menampilkan sample data dengan 5 baris pertama pada data `movie` yang dapat dilihat dari hasil diatas.
"""

# menampilkan informasi data pada Movie
movie.info()

"""**Menampilkan Informasi data Movie**

Pada tahap ini, penulis menggunakan fungsi `.head()` untuk menampilkan mengetahui jumlah baris dan kolom serta tipe data pada setiap kolom dalam `movie`. dari yang penulis ketahui bahwa :
- jumlah **Baris** : `9125` baris
- jumlah **kolom** : 3 kolom
- type data **object** ialah : `genres` dan `title`
- type data **int** ialah : `moveId`
"""

# Menampilkan statistik ringkasan pada Movie
movie.describe(include='all')

"""**Menampilkan struktur data statistik**

Pada tahap ini, penulis menggunakan fungsi `.decsribe(include='all')` untuk menampilkan semua struktur data statistik pada data `movie`. untuk melihat `jumlah data, mean, max, std dan persentase data`. dari yang penulis ketahui bahwa :     
- **jumlah data** sebanyak `9125.00 data`.
- nilai **min** ialah `1 data`.
- nilai **mean** ialah `31.123 data`.
- nilai **max** ialah `164.979 data`.
- pada kolom **genre** terdapat data `drama` muncul sebanyak 1.170 kali
- pada kolom **title** terdapat film yang sering muncul 2 kali ialah `Halmet (2000)`.

### Data Rating
"""

# menampilkan sample data rating dengan 5 baris pertama pada data `Rating`
rating.head(5)

"""**Menampilkan sample data**

Pada tahap ini, penulis menampilkan 5 baris pertama dalam data `rating` dengan menggunakan fungsi `.head()`. dari tampilan diatas, yang penulis lihat bahwa semua data dalam kolom **timestamp** berupa bilangan **integer** maka penulis perlu konversi tipe data pada kolom **timestamp**.
"""

# menampilkan informasi data rating
rating.info()

"""**Menampilkan Struktur data**

Pada tahap ini, penulis menggunakan fungsi `.info()` untuk melihat jumlah baris dan kolom serta tipe data dalam dataset `rating`. pada data informasi yang didapat bahwa
- jumlah **baris** sebanyak `100004 baris`.
- jumlah **kolom** sebanyak `4 kolom`.
- type data **int** ialah `userId`, `timestamp` dan `moveId`.
- type data **float** ialah `rating`
- melakukan konversi type data pada `timestamp` menjadi **datetime**

pada tahap ini dilakukan pada tahap data **preparation**.
"""

# menampilkan struktur statistik data pada rating.
rating.describe().T

"""**Menampilkan data statistik**

Pada tahap ini, penulis menggunakan fungsi `.describe()` untuk menampilkan dan mengetahui struktur data seperti `jumlah data, mean, max, std dan persentaset data` pada `rating`.

### Data Link
"""

# Menampilkan sample data pada data Link
link.head(5)

"""**Menampilkan Sample data pada data Link**

Pada tahap ini, penulis menggunakan fungsi `.head()` berfungsi untuk menampilkan sample data dengan 5 baris pertama dari data **link**.
"""

# Menampilkan informasi data pada data `Link`
link.info()

"""**Menampilkan Informasi data**

Pada tahap ini, penulis menggunakan fungsi `.info()` berfungsi untuk menampilkan informasi terkait data **link** yang dapat dilihat dari hasil diatas bahwa :     
- jumlah **baris** sebanyak `9125 baris`.
- jumlah **kolom** sebanyak `3 kolom`.
- type data **int** ialah `movieId` dan `imdbId`.
- type data **float** ialah `tmdbId`.
"""

# Menampilkan statistik data pada data `Link`
link.describe().T

"""**Menampilkan Statistik data**

Pada tahap ini, penulis menggunakan fungsi `.describe()` berfungsi untuk menampilkan semua data statistik pada data **link** yang dapat dilihat dari hasil diatas, dengan ini penulis mengetahui `jumlah data, mean, min, max, std dan persentase` pada data **link**.

### Data Tag
"""

# Menampilkan sample data pada data `tag`
tag.head(5)

"""**Menampilkan sample data**

Pada tahap ini, penulis menggunakan fungsi `.head()` berfungsi untuk menampilkan sample data pada data **tag** dengan 5 baris pertama.
"""

# Menampilkan statistik data `Tag`
tag.describe().T

"""**Menampilkan Statistik data tag**

Pada tahap ini, penulis menggunakan fungsi `.describe()`berfungsi untuk menampilkan statistik data pada data **tag** agar mengetahui `jumlah data, mean, min, max, std dan persentase` pada data **tag**
"""

# Menampilkan Informasi data `Tag`
tag.info()

"""**Menampilkan Informasi data tag**

Pada tahap ini, penulis menggunakan fungsi `.info()` untuk menampilkan informasi data pada data **tag**. dari yang diketahui bahwa :    
- jumlah **baris** sebanyak `1296 data`
- jumlah **kolom** sebanyak `4 kolom`
- type data **int** ialah `userId` dan `movieId` dan `timestamp`
- typedata **object** ialah `tag`.

###  Exploratory Data Analysis
"""

# Melihat Distribusi nilai rating setiap film
# Plot distribusi nilai rating
plt.figure(figsize=(8, 5))
sns.histplot(rating['rating'], bins=10, kde=False)
plt.title('Distribusi Nilai Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.grid(True)
plt.show()

"""**Visualisasi Distribusi Rating**

Pada tahap ini, penulis melakukan untuk menampilkan visualisasi distribusi rating. dari yang penulis ketahui bahwa distribusi condong kekanan (positif), mayoritas pengguna memberikan rating 3-5, tetapi rating terbanyak ialah rating 4 sebanyak 30.000 rating sedangkan rating 1 dan 2 memiliki jumlah yang sangat kecil dimana sedikit pengguna yang tidak menyukai film.
"""

# Menampilkan Distribusi film dari fitur genre.
movie_split = movie['genres'].dropna().str.split('|')

# Gabungkan semua list menjadi satu list datar
all_movies = list(chain.from_iterable(movie_split))

# Hitung frekuensi masing-masing judul
movie_counts = pd.Series(Counter(all_movies)).sort_values(ascending=False)
plt.figure(figsize=(12, 6))
sns.barplot(x=movie_counts.index[:10], y=movie_counts.values[:10], palette="Set2")  # Top 10 saja agar tidak terlalu padat
plt.xticks(rotation=45)
plt.title('Distribusi Jumlah Genre disukai pengguna')
plt.xlabel('Genre')
plt.ylabel('Jumlah')
plt.tight_layout()
plt.grid(True)
plt.show()

"""**Visualisasi Distribusi jumlah film berdasarkan genres**

Pada tahap ini, penulis melakukan visualisasi untuk menampilkan genre yang paling banyak. yang dapat penulis ketahui bahwa genre **drama** yang paling banyak mencapai `4000 film` diikuti oleh genre **Comedy** sebanyak `3000 film`. sedangkan genre yang paling sedikit diminati ialah **Horror, Sci-Fi,dan Fantasy** sebanyak `1000 film`.

## Data Processing

#### Menggabungkan data berdasarkan movieId
"""

# Menggabungkan seluruh movieID pada kategori movie_all
movie_all = np.concatenate((
    movie.movieId.unique(),
    rating.movieId.unique(),
    tag.movieId.unique(),
    link.movieId.unique(),
))

# Mengurutkan data dan menghapus data yang sama
movie_all = np.sort(np.unique(movie_all))

print('Jumlah seluruh variabel movie berdasarkan movieId: ', len(movie_all))

"""**Menampilkan Gabungan Variabel Movie**

Pada tahap ini, penulis melakukan penggabungan data unik `.MovieId` pada setiap data yang memiliki hubungan satu sama lain.seperti yang diketahui bahwa setelah penggabungan data unik, jumlah variabel movie berdasarkan `movieId` yaitu 9125.

### Menggabungkan data berdasarkan userId
"""

# Menggabungkan seluruh userId
user_all = np.concatenate((
    rating.userId.unique(),
    tag.userId.unique(),

))

# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all))

print('Jumlah seluruh user: ', len(user_all))

"""**Menampilkan Hasil Gabungan User**

Pada tahap ini menggabungkan data `userId` pada setiap variabel yang memiliki hubungan satu sama lain, yang dapat dilihat bahwa hasil jumlah data unik `userId` dari variabel **rating dan tag** sebanyak 671 data.

### Menggabungkan variabel rating berdasarkan movieId
"""

# Menampilkan seluruh variabel rating dari `movieId`.
all_movie_rate = rating
all_movie_rate

"""**Penggabungan data rating pada Dataframe baru**

Pada tahap ini, penulis melakukan penggabungan informasi rating film kedalam dataframe `all_movie_rate` dengan menampilkan informasi judul dan genre film dari variabel **movie** berdasarkan kode unik `movieId`.
"""

# menggabungkan file rating dan file movie menggunakan data movieId pada dataframe baru
# Pilih kolom yang ingin disertakan dari dataframe `movieId`
selected_columns = ['movieId', 'title', 'genres']
all_movie_name = pd.merge(all_movie_rate, movie[selected_columns], on='movieId', how='left')
all_movie_name

"""**Menggabungkan file rating dan file movie**

Pada tahap ini, penulis melakukan penggabungan informasi rating film dari dataframe `all_movie_rate` dengan menampilkan informasi judul dan genre film dari variabel **movie** berdasarkan kode unik `movieId`yang dimana akan disimpan dalam dataframe baru yaitu `all_movie_name`.
"""

# Mengecek apakah data mengalami missing value
print(all_movie_name.isnull().sum())

"""**Mengecek missing value**

Pada tahap ini, penulis menggunakan fungsi `.isnull()` untuk mengecek apakah data `all_movie_name` mempunyai nilai kosong. yang dapat penulis lihat bahwa data `all_movie_name` tidak memiliki nilai kosong, maka tidak perlu melakukan pada tahap **Data prepartion**.
"""

# Mencari rata rata rating tertinggi film
all_movie_name.groupby('title')['rating'].mean().sort_values(ascending=False).head(10)

"""**Menampilkan rating tertinggi**

Penulis melakukan untuk menampilkan banyaknya jumlah rating berdasarkan fitur genre, penulis dapat mengetahui bahwa judul film **Zerophilia (2005) sampai Drained (O cheiro do Ralo) (2006)** memiliki rating dengan 5.0.
"""

# Mencari rata rata rating terendah film
all_movie_name.groupby('title')['rating'].mean().sort_values(ascending=True).head(10)

"""**Menampilkan rating terendah**

Pada tahap ini, penulis melakukan untuk menampilkan rating terendah berdasarkan judul film, yang dapat diketahui bahwa judul film **Zombie Holocaust (a.k.a. Doctor Butcher M.D.) (Zombi Holocaust) (1980) sampai Santa with Muscies (1996)** memiliki rating terendah dengan rating 0.5 .

## Data Preparation
"""

# Mengkonversi tipe data `timestamp` menjadi datetime.
all_movie_name['timestamp'] = pd.to_datetime(all_movie_name['timestamp'], unit='s')
all_movie_name

"""**Konversi type data timestamp**

Pada tahap ini, penulis melakukan konversi type data pada kolom **timestamp** menjadi datetime.
"""

# mengurutkan data berdasarkan `movieId`
fix_movie = all_movie_name.sort_values('movieId', ascending=True)
len(fix_movie.movieId.unique())

"""**Mengurutkan data berdasarkan movieId**

Penulis melakukan untuk mengurutkan data berdasarkan kode unik yaitu `movieId` dan menampilkan jumlah data setelah mengurutkan data menggunakan fungsi `.shape()`
"""

# Membuang data duplikat pada variabel preparation
preparations = fix_movie.drop_duplicates('movieId')
preparations

"""**Menghapus Duplikat data**

Pada tahap ini, penulis melakukan untuk menghapus duplikat data berdasarkan kode unik `movieId` agar disaat melatih model tidak mengalami ketimpangan data.
"""

# Mengonversi data series ‘movieID’ menjadi dalam bentuk list
movie_id = preparations['movieId'].tolist()

# Mengonversi data series ‘title’ menjadi dalam bentuk list
title_movie = preparations['title'].tolist()

# Mengonversi data series ‘genres’ menjadi dalam bentuk list
genres_movie = preparations['genres'].tolist()

print(len(movie_id))
print(len(title_movie))
print(len(genres_movie))

"""**Konversi semua series ke bentuk `list`**

Pada tahap ini,penulis melakukan tahap konversi pada data `movieId, title dan genres` kedalam bentuk **list** serta menampilkan jumlah data series pada setiap data.
"""

# Membuat dictionary untuk data ‘movie_id’, ‘title’, dan ‘genres’
movie_new = pd.DataFrame({
    'movie_id': movie_id,
    'title': title_movie,
    'genre': genres_movie
})
movie_new

"""**Memasukkan ke Dict baru**

Pada tahap ini, penulis membuat dict baru pada data unik yang telah di konversi ke bentuk **list** dimana dari yang diketahui penulis membuat dict baru `movie_new` untuk latih model selanjutnya.

## Model 1 : Content Based Filtering
"""

# # Mengimpor TfidfVectorizer untuk mengubah teks menjadi vektor numerik berdasarkan frekuensi kata.
from sklearn.feature_extraction.text import TfidfVectorizer

# # Mengimpor fungsi untuk menghitung kemiripan antar vektor (misalnya antar film).
from sklearn.metrics.pairwise import cosine_similarity

# # Membuat objek TF-IDF yang akan mengabaikan kata-kata umum dalam bahasa Inggris
tfidf = TfidfVectorizer(stop_words='english')

# # Membersihkan kolom 'genres': menghapus tanda petik tunggal dan mengganti tanda pemisah '|' dengan spasi.
movie['genres'] = movie['genres'].str.replace(r"[']", "", regex=True).str.replace("|", " ")

# # Menggabungkan kolom 'title' dan 'genres' menjadi satu fitur teks untuk representasi film.
movie['features'] = movie['title'] + " " + movie['genres']

# menampilkan hasil dengan 6 baris pertama
movie.head(6)

"""**Menampikan rekomendasi film berdasarkan judul**

pada tahap ini, penulis melakukan pengubahan film dengan genre dan judul yang mirip akan nilai cosine similarity yang tinggi setelah itu, penulis menampilkan hasil dengan 5 film baris pertama yang paling mirip dengan dipilih oleh pengguna,
"""

# TF-IDF Vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tfidf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tfidf.fit(movie_new['genre'])

# Mapping array dari fitur index integer ke fitur nama
tfidf.get_feature_names_out()

"""**Transformasi data `genre`**

Pada tahap ini, penulis melakukan untuk mengubah data teks (dalam hal ini genre film) menjadi representasi numerik menggunakan metode **TF-IDF (Term Frequency-Inverse Document Frequency).**
"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tfidf.fit_transform(movie_new['genre'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""**Tampilan jumlah Transform data teks**

Penulis menampilkan jumlah data yang telah di transform kedalam numerik. dapat dilihat dari hasil diatas dimana hasilnya (9066, 24). Nilai 9066 merupakan ukuran data dan 24 merupakan matrik kategori judul film.
"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""**Menampilkan hasilnya kedalam matriks**

Penulis melakukan perubahan vector tf-idf kedalam bentuk matrik dengan menggunakan fungsi `todense()`.
"""

# Menampilkan representasi TF-IDF data teks pada dataframe `movie_new`
# mengambil sample data sebanyak 10 data.
pd.DataFrame(
    tfidf_matrix.todense(),  # title
    columns=tfidf.get_feature_names_out() ,
    index=movie_new.title
).sample(20, axis=1).sample(10, axis=0)

"""**Menampilkan hasil representasi TF-IDF**

Seperti yang diketahui, bahwa penulis menampilkan hasil representasi TF-IDF data teks dengan mengambil sample data sebanyak 10 data.
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""**Menghitung kesamaan**

Pada tahap ini, penulis menghitung kesamaan dari data yang telah di transform sebelumnya, dimana penulis menggunakan `cosine_similarity` sebagai fungsi untuk menghitung persamaan yang ada pada data.
"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa movie
cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_new['title'], columns=movie_new['title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap movie
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""**Menampilkan hasil**

pada tahap ini, penulis untuk melihat hasil matriks kesamaan setiap film dengan menampilkan judul film dalam ``5 sampel kolom (axis = 1)`` dan ``10 sampel baris (axis=0).``
"""

# menghitung kesamaan antar film atau membuat sistem rekomendasi sesuai genre.
tfidf_matrix = tfidf.fit_transform(movie['features'])
cosine_sims = cosine_similarity(tfidf_matrix, tfidf_matrix)
cosine_sims

"""**Tampilan Hasil cosine_similarity**

Pada tahap ini, penulis melakukan tahap tampilan hasil dari perhitungan `cosine_similarity` yang telah dibuat sebelumnya, pada fitur kolom **Feature** berfungsi untuk melihat kesamaan judul film yang direkomendasikan pengguna.

#### Melakukan Rekomendasi pada film
"""

# Fungsi untuk rekomendasi film (Content Based Filtering menggunakan Cosine Similarity)
def movie_recommendations(title, cosine_sim=cosine_sim):
    """Dapatkan rekomendasi film berdasarkan cosine similarity."""

    idx = movie[movie['title'] == title].index[0]  # Menemukan index film yang sesuai

    sim_scores = list(enumerate(cosine_sim[idx]))  # Menghitung similarity scores

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)  # Urutkan berdasarkan similarity

    sim_scores = sim_scores[1:11]  # Ambil 10 film teratas setelah film yang diminta

    movie_indices = [i[0] for i in sim_scores]  # Ambil indeks film yang relevan

    # Mengembalikan DataFrame film yang direkomendasikan
    return movie.iloc[movie_indices][['movieId', 'title', 'genres']]

"""**Membuat Rekomendasi pada movie**

Pada tahap ini, penulis melakukan pembuatan rekomendasi pada variabel **movie** berdasarkan `genre`. dengan menggunakan fungsi `similarity` untuk mengeksekusi movie yang sering muncul.
"""

# rekomendasi sample pertama
# menampilkan film dari dataframe df.
movie_new[movie_new.title.eq('Toy Story (1995)')]

"""**Menampilkan judul film**

Pada sample pertama ini, penulis melakukan tahapan untuk melihat salah satu film yang memiliki jenis genre terbanyak dari dataframe `df` sebelum melakukan rekomendasi film. pada hasil yang diketahui bahwa **Toy Story (1995)** memiliki genre **Adventure**.
"""

# membuat fungsi `movie_recomendations`
# untuk melihat banyaknya distribusi `genre` dari film tersebut.
movie_recommendations('Toy Story (1995)')

"""**Menampilkan Hasil Rekomendasi film**

Penulis melakukan tahapan untuk melihat rekomendasi film yang memiliki genre yang banyak diminati oleh pengguna, dari yang diketahui bahwa film **Toy Story (1995)** menjadi film yang banyak diminati oleh pengguna dengan genre yang dominan pada fil tersebut ialah **Adventure**.
"""

# rekomendasi sample kedua
# mengambil data `tittle` dari dataframe `df`.
movie_new[movie_new.title.eq('Jumanji (1995)')]

"""**Menampilkan judul film**

Pada sample kedua ini, penulis melakukan tahapan untuk melihat salah satu film yang banyak diminati oleh pengguna berdasarkan **genre**. dari yang diketahui bahwa film **Jumanji (1995)** ialah film yang diminati pengguna setelah ``Jumanji (1995)`` dengan genre yang dominan ialah genre **Adventure.**
"""

# melakukan fungsi `movie_recomendation`
# untuk melihat jumlah distribusi `genre` dari film tersebut.
movie_recommendations('Jumanji (1995)')

"""**Menampilkan hasil Rekomendasi film**

Pada tahap ini, penulis melakukan hasil pencarian sebelumnya kedalam fungsi ``recomendation_movie`` untuk mengetahui berapa banyak kontrubusi genre dari film **Jumanji (1995)**, yang dapat diketahui bahwa jumlah genre dari film tersebut memiliki jumlah genre yang paling banyak diminati oleh pengguna.

### Model 2 Collaborative Filtering

Pada Tahap ini, Penulis melakukan untuk melatih model pada model ke-2 **Collaborative Filtering**. pada analisa lebih lanjut pada model ini, penulis perlu melakukan **tahap preparation**.

### Data Preparation
"""

# mengeksekusi variabel rating dati dataframe `df`
df = rating
df

# Mengubah userID menjadi list tanpa nilai yang sama
user_id = df['userId'].unique().tolist()
print('list userId: ', user_id)

# melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_id)}
print('encoded userId : ', user_to_user_encoded)

# melakukan proses encoding angka ke userId
user_encoded_to_user = {i: x for i, x in enumerate(user_id)}
print('encoded angka ke userId: ', user_encoded_to_user)

"""**Mengubah data userId ke list**

Penulis melakukan untuk mengubah data `userId` menjadi list dengan menggunakan fungsi `.tolist()` dan `encoded` berfungsi konveri data ke dalam numerik.
"""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()
print('list movieId: ', movie_ids)

# melakukan encoding userID
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
print('encoded movieId : ', movie_to_movie_encoded)

# melakukan proses encoding angka ke userID
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke movieId: ', movie_encoded_to_movie)

"""**Mengubah data movieId ke list**

Penulis melakukan untuk mengubah data `movieId` menjadi list menggunakan fungsi `.tolist()` dan `encoded` berfungsi untuk mengubah data kedalam numerik.
"""

# melakukan mapping pada userId.
# Mapping userId ke dataframe df
df['userId'] = df['userId'].map(user_to_user_encoded)

# Mapping movieId ke dataframe df
df['movieId'] = df['movieId'].map(movie_to_movie_encoded)

"""**Melakukan Mapping**

Penulis melakukan tahapan mapping pada ``userId dan movieId`` dengan menggunakan fungsi ``.map``
"""

# melihat jumlah data yang telah di encoded.
num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df['rating'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])

max_rating = max(df['rating'])

print('Number of User: {}, Number of movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""**Tampilan hasil jumlah**

Penulis menampilkan untuk melihat hasil jumlah dari ``userId dan movieId`` setelah melakukan **mapping** sebelumnya. bahwa yang diketahui :    
- jumlah ``userId`` ialah 671 data
- jumlah ``movieId`` ialah 9066 data.

### Training dan Validasi
"""

# membagi data untuk training.
# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data genres  dan movies menjadi satu value
x = df[['userId', 'movieId']].values

# Membuat variabel y untuk membuat ratings dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""**Pembagian data**

Penulis melakukan pembagian data untuk melakukan pelatihan model selanjutnya dengan menggunakan fungsi ``Tensorflow Keras``.dari yang diketahui bahwa :    
- **x** diambil dari data **`movieId dan userId`**
- **y** diambil dari data **`rating`** dengan menghitung jumlah ``min dan max`` dari **`rating`** tersebut.
- dibagi menjadi 80% data train dan 20% data validation
- setelah dibagi, maka diubah menjadi matriks.
"""

# menampilkan jumlah dataset yang telah dagi sebelumnya.
print(f'Total keseluruhan dataset : {len(x)}')
print(f'Total train dataset : {len(x_train)}')
print(f'Total test dataset : {len(x_val)}')

"""**Tampilan jumlah dataset**

Penulis melakukan untuk mengetahui keseluruhan data yang telah dibagi sebelumnya, dari yang diketahui bahwa :    
- Total keseluruhan dataset : 100004
- Total train dataset : 80003
- Total test dataset : 20001
"""

# Build class RecommenderNet
class RecommenderNet(tf.keras.Model):

    def __init__(self, num_users, num_movie, embedding_size=50, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_movie = num_movie
        self.embedding_size = embedding_size

        # User embedding
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)

        # Book embedding
        self.movie_embedding = layers.Embedding(
            num_movie,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.movie_bias = layers.Embedding(num_movie, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        movie_vector = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])

        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)
        x = dot_user_movie + user_bias + movie_bias

        return tf.nn.sigmoid(x)

"""**Melatih Item-filtering dan User-filtering**

Pada tahap ini, penulis melakukan latih model pada **item-filtering** dan **user-filtering** dengan menggunakan fungsi ``embedding`` pada model yang akan dilatih dari library **Tensorflow Keras**.

### Evaluasi Model

- **Evaluasi Model 1 : Content-Based-Filtering**
"""

# Fungsi evaluasi baru untuk Content-Based Filtering
def precision_recall_content_based(input_movie, movie_recommendations, k=10):
    input_tfidf = tfidf.transform([input_movie])
    rec_tfidf = tfidf.transform(movie_recommendations)

    # Menghitung cosine similarity antara input dan rekomendasi
    sim_scores = cosine_similarity(input_tfidf, rec_tfidf)[0]

    # Menghitung precision dan recall berdasarkan similarity scores
    precision = sum(sim_scores[:k]) / k
    recall = sum(sim_scores[:k]) / sum(sim_scores) if sum(sim_scores) > 0 else 0

    # Mengembalikan nilai precision dan recall dalam persentase
    return precision * 100, recall * 100

# Contoh penggunaan evaluasi untuk dua film input
input_movies = ["Toy Story (1995)", "Jumanji (1995)"]
recommendation_results = {movie: list(movie_recommendations(movie)['title']) for movie in input_movies}

for movie in input_movies:
    recommended_titles = recommendation_results[movie]
    precision, recall = precision_recall_content_based(movie, recommended_titles, k=5)
    print(f"Precision@5 for '{movie}': {precision:.2f}%")
    print(f"Recall@5 for '{movie}': {recall:.2f}%")

"""**Keimpulan :**

Pada Evaluasi dari model 1 yaitu **Content-Based-Filtering** yang dapat diketahui ialah jumlah akurasi dari model tersebut mencapai 100%, dari nilai **F-1** mencapai 100%, nilai **Precision** mencapai 100%, milai **Recall** mencapai 100%.maka model pertama mendapatkan hasil sempurna.

**Evaluasi Model Collaborative-Based-Filtering**
"""

# Inisialisasi model
model = RecommenderNet(num_users, num_movie, embedding_size=50)

# Compile model
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

from tensorflow.keras.callbacks import EarlyStopping

# Setup EarlyStopping
early_stop = EarlyStopping(
    monitor='val_root_mean_squared_error', # Monitor validasi RMSE
    patience=5, # Tunggu 5 epoch berturut-turut, kalau nggak improve, stop
    restore_best_weights=True # Balikin ke model dengan bobot terbaik
)

# Retraining dengan EarlyStopping
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=8,
    epochs=100,
    validation_data=(x_val, y_val),
    callbacks=[early_stop]
)

# menampilkan plot hasil evaluasi.
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('Root Mean Squared Error')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.grid(True)
plt.show()

"""**Insight :**

Dari hasil evaluasi yang didapat dari model kedua yaitu **Collaborative-Filtering**. yang dapat diketahui bahwa nilai training RMSE menunjukkan model berhasil **mempelajari pola dari data pelatihan dengan baik** sedangkan nilai validation RMSE mengalami **indikasi awal overfitting** dimana model terus membaik didata pelatihan tetapi tidak lagi membaik didata validasi.
"""

# Inisialisasi Data
movie_df = movie_new
df = pd.read_csv('ratings.csv')

# mengambil Salah Satu User Secara Acak
user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]

# mengambil Film yang Sudah Ditonton oleh User
movie_not_watched = movie_df[~movie_df['movie_id'].isin(movie_watched_by_user.movieId.values)]['movie_id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)
# menampilkan hasil Filter Film yang Belum Pernah Ditonton
movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

# memprediksi Rating untuk Film yang Belum Ditonton
ratings = model.predict(user_movie_array).flatten()

# mengambil 10 Film Teratas Berdasarkan Prediksi
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

# menampilkan rekomendasi film
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movie with high ratings from user')
print('----' * 8)

# Menampilkan Film dengan Rating Tertinggi dari User
top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

# Menampilkan 10 Rekomendasi Film untuk User
movie_df_rows = movie_df[movie_df['movie_id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.genre)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movie = movie_df[movie_df['movie_id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genre)

"""**Insight**

Pada tahap ini, penulis melakukan untuk menampilkan jumlah film yang diberikan rating tinggi oleh pengguna. dari hasil diatas yang ditampilkan bahwa pengguna yang memberikan rating tertinggi dari film ialah :  

--------------------------------
- Film : Crimson Tide (1995) dengan genre *Drama|Thriller|War* <br>
- Film Catch Me If You Can (2002) dengan genre *Crime|Drama*<br>
- Film Chicago (2002) dengan genre Comedy|Crime|Drama|Musical*<br>
- Film King of Comedy, The (1983) dengan genre *Comedy|Drama*<br>
- Film Long, Hot Summer, The (1958) dengan genre *Drama*
--------------------------------

dari yang dapat disimpulkan bahwa genre terbanyak yang banyak diminati oleh user ialah : *``Drama, Crime, Comedy dan Musical``*.
"""

# report evaluasi model ()
model.evaluate(x,y)

# Import library yang dibutuhkan
from sklearn.metrics import mean_absolute_error
import numpy as np

# Melakukan prediksi
predicted_y = model.predict(x)

# Menghitung MSE
# Menghitung MAE
mae = mean_absolute_error(y, predicted_y)
print("MAE:", mae)

# Menghitung RMSE secara manual
rmse = np.sqrt(mae)

# Menampilkan hasil
print(f"Mean Squared Error (MAE): {mae:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

mae

rmse

"""**Menampilkan nilai error**

Pada tahap ini, penulis menampilkan hasil nilai error dari **``RMSE dan MSE``**, yang dapat diketahui bahwa dari hasil diatas adalah nilai **RMSE** sebanyak 0,218 yang dimana menunjukkan selisih antara prediksi dan nilai aktual pada kesalahan prediksi yang rendah dan nilai **MSE** sebanyak 0,047 yang menunjukkan nilai MSE cukup rendah dan prediksi model cukup akurat yang berada dengan nilai aktual user.
"""

# Membuat list genre unik dari data
user_genres = []
list_movie_genres = movie_df_rows.genre.unique()

for genre in list_movie_genres:
    user_genres.extend(genre.split(', '))

# Ambil genre unik dan urutkan
user_genres = sorted(set(user_genres))

# Inisialisasi dictionary untuk menghitung jumlah genre
total_genre_by_user = {genre: 0 for genre in user_genres}

# Hitung total kemunculan tiap genre
for movie_genre in movie_df_rows['genre']:
    list_genres = movie_genre.split(', ')
    for genre in list_genres:
        total_genre_by_user[genre] += 1

# Urutkan berdasarkan jumlah kemunculan (descending)
total_genre_by_user = dict(sorted(total_genre_by_user.items(), key=lambda x: x[1], reverse=True))

# Plot bar chart untuk 10 genre teratas
plt.figure(figsize=(12, 8))
sns.barplot(
    x=list(total_genre_by_user.keys())[:10],
    y=list(total_genre_by_user.values())[:10],
    palette="viridis"
)
plt.xticks(rotation=45)
plt.title("Diagram Top Genre yang Disukai User")
plt.xlabel("Genre")
plt.ylabel("Jumlah Kemunculan")
plt.tight_layout()
plt.show()

"""**Hasil Visualisasi**

setelah penulis melakukan tampilan hasil prediksi genre yang disukai oleh user dari rating tertinggi, maka penulis melakukan hasil visualisasinya dengan menggunakan bar chart untuk melihat secara jelas genre yang **paling banyak diminati** oleh user.
"""

# Ekstraksi semua genre unik dari data rekomendasi
recommended_genres = []
list_movie_genres = recommended_movie.genre.unique()

for genre_string in list_movie_genres:
    recommended_genres.extend(genre_string.split(', '))

# Ambil hanya genre unik
recommended_genres = sorted(set(recommended_genres))

# Inisialisasi dictionary untuk menghitung jumlah genre
total_genre_by_recommendation = {genre: 0 for genre in recommended_genres}

# Hitung jumlah kemunculan tiap genre dari data rekomendasi
for movie_genre in recommended_movie['genre']:
    list_movie_genre = movie_genre.split(', ')
    for genre in list_movie_genre:
        total_genre_by_recommendation[genre] += 1

# Urutkan berdasarkan frekuensi (descending)
total_genre_by_recommendation = dict(sorted(
    total_genre_by_recommendation.items(),
    key=lambda x: x[1],
    reverse=True
))

# Plot top 10 genre
plt.figure(figsize=(12, 8))
sns.barplot(
    x=list(total_genre_by_recommendation.keys())[:10],
    y=list(total_genre_by_recommendation.values())[:10],
    palette="coolwarm"
)
plt.xticks(rotation=90)
plt.title("Diagram Top 5 Recommendation Genre Movie")
plt.xlabel("Genre")
plt.ylabel("Jumlah Kemunculan")
plt.tight_layout()
plt.show()

"""**Visualisasi Genre**

Pada tahap ini, penulis melakukan hasil visualisasi dari rating tertinggi berdasarkan genre yang diminati oleh user, dari yang dapat diketahui bahwa genre yang paling banyak disukai oleh user ialah **Drama, Comedy, Crime dan Documentary**.

### Kesimpulan
- **Content-Based Filtering** hampir sama dengan analisis sentimen dimana sebagai pendekatan awal namun performa dalam memberikan rekomendasi pada user terbatas karena hanya mengandalkan judul film berdasarkan fitur **genre**. hasil evaluasi model yang didapat dengan menggunakan *Precision@K5 dan Recall@K5* memberikan nilai yang akurat serta memberikan rekomendasi film yang relevan untuk pengguna. dari 2 contoh film input yang di evaluasi yaitu **``Toy Story (1995) dan Jumanji (1995)``** mendapatkan hasil sebagai berikut <br>

| Film               | Precision@5 | Recall@5 |
|--------------------|-------------|----------|
| Toy Story (1995)   | 16.60%      | 100.00%  |
| Jumanji (1995)     | 2.62%       | 100.00%  |

<br>

- **Collaborative Filtering** memberikan hasil evaluasi dengan hasil terbaik serta performa yang baik dalam menangkap pola laten preferensi pengguna, dengan menggunakan 2 metrik pada model yaitu **RMSE dan MAE** yang menujukkan nilai error yang rendah dan performa yang baik pada model.
"""